import streamlit as st
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
from audio_recorder_streamlit import audio_recorder
import io

# 1. ç¶²é é é¢è¨­å®š (è¨­å®šç€è¦½å™¨åˆ†é æ¨™é¡Œèˆ‡åœ–ç¤º)
st.set_page_config(page_title="IEYI AI Voice Detector", page_icon="ğŸ›¡ï¸", layout="wide")

# --- éŸ³æ•ˆæ’­æ”¾å‡½å¼ ---
def play_audio_effect(is_ai):
    # åˆ¤å®šç‚º AI æ™‚æ’­æ”¾è­¦å ±éŸ³ï¼ŒçœŸäººå‰‡æ’­æ”¾å®å’šè²
    sound_url = "https://www.soundjay.com/buttons/sounds/button-10.mp3" if is_ai else "https://www.soundjay.com/buttons/sounds/button-37.mp3"
    sound_html = f"""
        <audio autoplay>
            <source src="{sound_url}" type="audio/mp3">
        </audio>
    """
    st.components.v1.html(sound_html, height=0)

# 2. è‡ªå®šç¾©æ¥µè‡´ç¾åŒ– CSS (åŒ…å«å‹•æ…‹ç‹¼é ­èˆ‡åç‰Œæ¨£å¼)
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+TC:wght@400;700&display=swap');
    html, body, [data-testid="stSidebar"] { font-family: 'Noto Sans TC', sans-serif; }
    
    /* åœ˜éšŠåç‰Œæ¨£å¼ */
    .team-header {
        background: linear-gradient(135deg, #1e3a8a 0%, #3b82f6 100%);
        color: white; padding: 30px; border-radius: 20px;
        text-align: center; box-shadow: 0 10px 25px rgba(0,0,0,0.2);
        margin-bottom: 35px;
    }
    .member-box {
        display: inline-block; background: rgba(255,255,255,0.15);
        padding: 12px 25px; border-radius: 12px; margin: 8px;
        border: 1px solid rgba(255,255,255,0.4);
        line-height: 1.6;
    }

    /* çµæœé¡¯ç¤ºå¡ç‰‡ */
    .result-container {
        padding: 40px; border-radius: 25px; text-align: center;
        margin: 25px 0; color: white; transition: 0.5s;
    }
    .safe-card {
        background: linear-gradient(145deg, #166534, #22c55e);
        box-shadow: 0 0 35px rgba(34, 197, 94, 0.4);
    }
    .warning-card {
        background: linear-gradient(145deg, #991b1b, #ef4444);
        box-shadow: 0 0 55px rgba(239, 68, 68, 0.7);
        animation: wolf-shake 0.4s infinite;
    }
    @keyframes wolf-shake {
        0% { transform: scale(1) rotate(0deg); }
        25% { transform: scale(1.03) rotate(-1deg); }
        75% { transform: scale(1.03) rotate(1deg); }
        100% { transform: scale(1) rotate(0deg); }
    }
    .wolf-head { font-size: 130px; filter: drop-shadow(0 0 15px black); margin-bottom: 10px; }
    
    /* æŒ‡æ¨™æ•¸æ“šç¾åŒ– */
    .stMetric { background: white; border-radius: 15px !important; box-shadow: 0 6px 12px rgba(0,0,0,0.08) !important; padding: 20px !important; }
    </style>
    """, unsafe_allow_html=True)

# 3. åœ˜éšŠåç‰Œ (å®Œæ•´å‘ˆç¾å­¸æ ¡å…¨ç¨±èˆ‡å­¸ç”Ÿå§“å)
st.markdown("""
    <div class="team-header">
        <h1 style='margin-bottom:5px; font-size: 40px;'>ğŸ›¡ï¸ AI èªéŸ³é˜²è©é¨™å³æ™‚åµæ¸¬ç³»çµ±</h1>
        <p style='opacity:0.9; font-size:20px; letter-spacing: 2px;'>2026 IEYI ä¸–ç•Œé’å°‘å¹´ç™¼æ˜å±• - ç«¶è³½å±•ç¤ºç‰ˆ</p>
        <div style='margin-top:20px;'>
            <div class="member-box">ğŸ« <b>æ–°åŒ—å¸‚ç§ç«‹æ—å£åº·æ©‹åœ‹éš›å­¸æ ¡</b><br>èŒƒæ‡¿é£› George</div>
            <div class="member-box">ğŸ« <b>å°åŒ—å¸‚ç§ç«‹å»¶å¹³ä¸­å­¸</b><br>èŒƒå¤ç¿” Charles</div>
            <div class="member-box">ğŸ« <b>å°åŒ—å¸‚ç§ç«‹è¡›ç†å¥³ä¸­</b><br>èŒƒç‘€åª— Rose</div>
        </div>
    </div>
    """, unsafe_allow_html=True)

# æ ¸å¿ƒåˆ†æåŠŸèƒ½
def process_audio(audio_bytes, title):
    if audio_bytes:
        audio_segment = io.BytesIO(audio_bytes)
        try:
            # è®€å–éŸ³è¨Šä¸¦è¨ˆç®—ç§’æ•¸
            y, sr = librosa.load(audio_segment, sr=16000)
            duration = len(y) / sr
            
            if duration < 0.5:
                st.warning("âš ï¸ éŒ„éŸ³é•·åº¦ä¸è¶³ï¼Œè«‹è‡³å°‘éŒ„è£½ 1 ç§’ä»¥ä¸Šã€‚")
                return

            # --- è²å­¸ç‰¹å¾µè¨ˆç®— ---
            rms = np.mean(librosa.feature.rms(y=y))
            zcr = np.mean(librosa.feature.zero_crossing_rate(y=y))
            mfcc_feat = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            mfcc_var = np.var(mfcc_feat)

            # --- å¤šç¶­åº¦åˆ¤å®šé‚è¼¯ (é‡å°å¯¦æ¸¬æ•¸æ“šå„ªåŒ–) ---
            ai_score = 0
            reasons = []
            if zcr < 0.115: 
                ai_score += 1
                reasons.append("é »ç‡éš¨æ©Ÿæ€§åä½ (ZCR ä½æ–¼å®‰å…¨é–€æª»)")
            if mfcc_var < 10400: 
                ai_score += 1
                reasons.append("éŸ³è‰²ç‰¹å¾µè®Šç•°æ•¸ä¸è¶³ (MFCC æŒ‡ç´‹éæ–¼å–®ä¸€)")
            if zcr < 0.095: 
                ai_score += 1
                reasons.append("åµæ¸¬åˆ°æ˜é¡¯æ•¸ä½åˆæˆç—•è·¡")

            # --- çµæœé¡¯ç¤ºå€ ---
            st.info(f"â±ï¸ **åˆ†æå®Œæˆï¼éŸ³è¨Šç¸½é•·åº¦ï¼š{duration:.2f} ç§’**")
            
            if ai_score >= 2:
                play_audio_effect(True) # æ’­æ”¾ AI è­¦å ±éŸ³
                st.markdown(f"""
                <div class="result-container warning-card">
                    <div class="wolf-head">ğŸº</div>
                    <h1 style='font-size:48px; margin:0;'>DANGER: AI VOICE DETECTED</h1>
                    <p style='font-size:26px;'>åµæ¸¬åˆ°é«˜åº¦è©é¨™é¢¨éšªï¼(åˆ¤å®šå¾—åˆ†: {ai_score}/3)</p>
                </div>
                """, unsafe_allow_html=True)
                with st.expander("ğŸ“ è©³ç´°ç§‘å­¸åˆ¤å®šä¾æ“š"):
                    st.write(f"ç³»çµ±åµæ¸¬åˆ°ä»¥ä¸‹ç•°å¸¸ç‰¹å¾µï¼š**{', '.join(reasons)}**ã€‚")
                    st.write("é€™ä»£è¡¨è©²éŸ³è¨Šç¼ºä¹çœŸäººè²å¸¶åœ¨èªªè©±æ™‚è‡ªç„¶ç”¢ç”Ÿçš„ã€ç‰©ç†éš¨æ©Ÿæ€§ã€èˆ‡ã€è«§æ³¢è±å¯Œåº¦ã€ã€‚")
            else:
                play_audio_effect(False) # æ’­æ”¾çœŸäººæˆåŠŸéŸ³
                st.markdown(f"""
                <div class="result-container safe-card">
                    <div style="font-size:110px;">ğŸ›¡ï¸</div>
                    <h1 style='font-size:48px; margin:0;'>SAFE: HUMAN VOICE</h1>
                    <p style='font-size:26px;'>åˆ¤å®šç‚ºçœŸå¯¦äººè²ã€‚æœªåµæ¸¬åˆ°æ•¸ä½åˆæˆè·¡è±¡ã€‚</p>
                </div>
                """, unsafe_allow_html=True)

            # --- æ•¸æ“šå„€è¡¨æ¿ ---
            st.markdown("### ğŸ“Š é—œéµè²å­¸æ•¸æ“šåº«")
            c1, c2, c3 = st.columns(3)
            c1.metric("RMS (èƒ½é‡å¼·åº¦)", f"{rms:.4f}")
            c2.metric("ZCR (é »ç‡éš¨æ©Ÿæ€§)", f"{zcr:.4f}")
            c3.metric("MFCC Var (éŸ³è‰²è±å¯Œåº¦)", f"{mfcc_var:.1f}")

            # --- è¦–è¦ºåŒ–åœ–è¡¨ ---
            st.markdown("---")
            col_a, col_b = st.columns(2)
            with col_a:
                st.caption("ğŸ“ˆ **Time Domain (æ™‚é–“åŸŸæ³¢å½¢ - èƒ½é‡åˆ†ä½ˆ)**")
                fig, ax = plt.subplots(figsize=(10, 4))
                librosa.display.waveshow(y, sr=sr, ax=ax, color='#3b82f6')
                ax.set_axis_off()
                st.pyplot(fig)
            with col_b:
                st.caption("ğŸŒˆ **Spectrogram (é »è­œåœ– - è«§æ³¢æŒ‡ç´‹)**")
                fig2, ax2 = plt.subplots(figsize=(10, 4))
                S = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
                librosa.display.specshow(S, sr=sr, ax=ax2, x_axis='time', y_axis='hz', cmap='magma')
                ax2.set_axis_off()
                st.pyplot(fig2)

        except Exception as e:
            st.error(f"åˆ†æç™¼ç”Ÿä¸å¯é æœŸçš„éŒ¯èª¤: {e}")

# 5. åˆ†é ä¸»ä»‹é¢
tab_rec, tab_file = st.tabs(["ğŸ™ï¸ ç¾å ´åµæ¸¬ (Live Record)", "ğŸ“‚ æª”æ¡ˆåˆ†æ (Upload File)"])

with tab_rec:
    st.write("è«‹é»æ“Šéº¥å…‹é¢¨å¾Œé–‹å§‹èªªè©±ï¼ˆå»ºè­°éŒ„è£½ 3-5 ç§’ï¼‰ï¼š")
    audio_data = audio_recorder(text="", recording_color="#ef4444", icon_size="3x")
    if audio_data:
        process_audio(audio_data, "ç¾å ´éŒ„éŸ³")

with tab_file:
    file = st.file_uploader("é¸æ“‡æ¬²åˆ†æçš„éŸ³è¨Šæª”æ¡ˆ (.wav/mp3/m4a)", type=['wav','mp3','m4a'])
    if file:
        process_audio(file.read(), "æª”æ¡ˆä¸Šå‚³åˆ†æ")